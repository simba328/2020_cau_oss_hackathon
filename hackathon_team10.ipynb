{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hackathon_team10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1AosAX9DXOlc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simba328/2020_cau_oss_hackathon/blob/master/hackathon_team10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1AosAX9DXOlc"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        "*   모든 구현은 [2. 데이터 전처리] 및 [3.모델 생성]에서만 진행\n",
        "*   [4. 모델 저장]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *    트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임->모든 런타임 재설정\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        " *  모델 발표 자료 \n",
        "* 제출 기한: **오후 5시 (단, 발표자료는 11시)**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2020_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드 or 알고리즘이 적발될 경우\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67lwEXhUqys1"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ms5PBBJ1qSC6",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "check = !if [ -d 'dataset/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (check[0] is '0' ):\n",
        "  !mkdir dataset\n",
        "  !wget 'https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip'\n",
        "  !unzip matlab.zip -d /content/dataset\n",
        "\n",
        "# 데이터셋 로드\n",
        "from scipy import io as spio\n",
        "emnist = spio.loadmat(\"/content/dataset/matlab/emnist-balanced.mat\")\n",
        "\n",
        "x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
        "y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
        "\n",
        "x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
        "y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
        "\n",
        "# # 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 데이터 28x28 이미지화\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A-YjppJpXBO9"
      },
      "source": [
        "# **2. 데이터 전처리**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZ9KWTBP6AI1",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        zoom_range = 0.1, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "x_train_after = x_train\n",
        "x_test_after = x_test"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v-lo-O1yiFpY"
      },
      "source": [
        "# **3. 모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h_fEIVsv-kH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST 데이터 로드\n",
        "(mx_train, my_train), (mx_test, my_test) = mnist.load_data()\n",
        "\n",
        "mx_train = mx_train.astype('float32').reshape([*mx_train.shape, 1])\n",
        "mx_test = mx_test.astype('float32').reshape([*mx_test.shape, 1])\n",
        "\n",
        "mnum_classes = 10\n",
        "my_train = np_utils.to_categorical(my_train,mnum_classes)\n",
        "my_test = np_utils.to_categorical(my_test,mnum_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q0vErsPwzOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST 모델 생성\n",
        "input_shape = (28, 28, 1)\n",
        "mnist_model = Sequential()\n",
        "mnist_model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\n",
        "mnist_model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\n",
        "mnist_model.add(MaxPool2D((2, 2)))\n",
        "mnist_model.add(Dropout(0.25))\n",
        "mnist_model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "mnist_model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "mnist_model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "mnist_model.add(Dropout(0.25))\n",
        "\n",
        "mnist_model.add(Flatten())\n",
        "mnist_model.add(Dense(256, activation = \"relu\"))\n",
        "mnist_model.add(Dropout(0.5))\n",
        "mnist_model.add(Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNJ0HQcbxFYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST 모델 학습\n",
        "batch_size = 128\n",
        "mnum_classes = 10\n",
        "epoch = 50\n",
        "\n",
        "opt_adm = keras.optimizers.Adadelta(lr=0.1)\n",
        "mnist_model.compile(loss='categorical_crossentropy', optimizer=opt_adm, metrics=['accuracy'])\n",
        "train = model.fit_generator(datagen.flow(mx_train, my_train, batch_size=batch_size),\n",
        "                                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=epoch,\n",
        "                                    verbose=1,validation_data=(mx_test,my_test))\n",
        "mnist_model.save(\"mnist_model.h5\")\n",
        "print(train.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVqleGsKyPE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST 데이터셋으로 학습한 모델 불러오기\n",
        "transfer_model=load_model('mnist_model.h5')\n",
        "\n",
        "feature_layers = [\n",
        "    Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape),\n",
        "    Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'),\n",
        "    MaxPool2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'),\n",
        "    Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten()\n",
        "]\n",
        "classification_layers = [\n",
        "    Dense(256, activation = \"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation = \"softmax\")\n",
        "]\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnYHFzSKy5zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델생성 및 transfering\n",
        "weights= [layer.get_weights() for layer in transfer_model.layers]\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(47, activation = \"softmax\"))\n",
        "\n",
        "for i in np.arange(0,len(feature_layers),1):\n",
        "    model.layers[i].set_weights(weights[i])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMf4UCnXy_ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epoch = 100\n",
        "\n",
        "opt_adm = keras.optimizers.Adadelta(lr=0.1)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_adm, metrics=['accuracy'])\n",
        "train = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=epoch,\n",
        "                                    verbose=1,validation_data=(x_test,y_test))\n",
        "print(train.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QR9WUYXxqtfR"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wi9yznz4qvzK",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team10'\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_'+ team_name + '.h5')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4aPbgI-c-Kj8"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7WONVxH-Kt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "564afade-8858-47b3-8b9a-f1b74712bd4e"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team10'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'model_entire_' + team_name + '.h5')\n",
        "\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33276453614234924, 0.8871276378631592]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    }
  ]
}